# Retrieval

:::info[Prerequisites]

* [Retrievers](/docs/concepts/retrievers/)
* [Vector stores](/docs/concepts/vectorstores/)
* [Embeddings](/docs/concepts/embedding_models/)
* [Text splitters](/docs/concepts/text_splitters/)

:::

:::danger[Security]
 
ここで取り上げた概念の中には、モデルを使用してクエリ（例：SQLやグラフデータベース用）を生成するものがあります。  
これには固有のリスクが伴います。  
アプリケーションのニーズに応じて、データベース接続の権限範囲を可能な限り狭く設定してください。  
これにより、データベースをクエリできるモデル駆動型システムを構築する際のリスクを軽減できますが、完全に排除することはできません。  
一般的なセキュリティのベストプラクティスについては、[セキュリティガイド](/docs/security)をご覧ください。

:::

## 概要

検索システムは、多くのAIアプリケーションにとって基本的な要素であり、大規模なデータセットから関連情報を効率的に特定します。
これらのシステムは、さまざまなデータ形式に対応しています：

- 非構造化テキスト（例：ドキュメント）は、ベクトルストアやレキシカル検索インデックスに格納されることが多いです。
- 構造化データは、通常、スキーマが定義されたリレーショナルデータベースやグラフデータベースに格納されます。

データ形式が多様化しているにもかかわらず、現代のAIアプリケーションは、すべての種類のデータを自然言語インターフェースを通じて利用可能にすることをますます目指しています。  
このプロセスで、モデルは自然言語クエリを基盤となる検索インデックスやデータベースに対応する形式に変換する重要な役割を果たします。  
この変換により、複雑なデータ構造との直感的で柔軟な対話が可能になります。

## 重要な概念

![Retrieval](/static/img/retrieval_concept.png)

(1) **Query analysis**: モデルが検索クエリを変換または構築し、検索効率を最適化するプロセス。

(2) **Information retrieval**: 検索クエリを使用して、さまざまな検索システムから情報を取得するプロセス。

## Query analysis 

ユーザーは通常、自然言語を使用して検索システムと対話することを好みますが、これらのシステムは特定のクエリ構文を必要とする場合や、特定のキーワードを活用することで効果が向上する場合があります。  
クエリ分析は、生のユーザー入力と最適化された検索クエリの間の橋渡しをします。  
クエリ分析の一般的な応用例には以下があります：

1. **Query Re-writing**: クエリを再構築または拡張して、セマンティックまたはレキシカル検索を改善します。
2. **Query Construction**: 検索インデックスは構造化クエリを必要とする場合があります（例：データベース用のSQL）。

クエリ分析は、モデルを使用して生のユーザー入力から最適化された検索クエリを変換または構築するために使用されます。

### Query re-writing

検索システムは、単純で不明瞭なクエリから複雑で多面的な質問まで、幅広いユーザー入力に対応することが理想的です。  
この柔軟性を実現するための一般的なアプローチは、生のユーザークエリをより効果的な検索クエリに変換するためにモデルを使用することです。  
この変換は、単純なキーワード抽出から高度なクエリ拡張や再構築までさまざまです。  

非構造化データ検索におけるクエリ分析でモデルを使用する主な利点は以下の通りです：
1. **Query Clarification**: モデルは曖昧または不明瞭なクエリを明確に書き換えることができます。
2. **Semantic Understanding**: モデルはクエリの意図を捉え、単純なキーワードの一致を超えた検索を可能にします。
3. **Query Expansion**: モデルは関連する用語や概念を生成して検索範囲を広げることができます。
4. **Complex Query Handling**: モデルは、多面的な質問を単純なサブクエリに分解できます。

クエリの書き換えにモデルを活用するために、さまざまな技術が開発されています。これには以下が含まれます：

| 名前                                                                                                      | 使用する場面                                                                                    | 説明                                                                                                                                                                                                                                                                            |
|-----------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Multi-query](/docs/how_to/MultiQueryRetriever/)                                                          | 質問を複数の表現で提示することで検索の高い網羅性を確保したい場合 | ユーザーの質問を複数の表現で書き換え、それぞれの書き換えられた質問でドキュメントを取得し、すべてのクエリに対してユニークなドキュメントを返します。                                                                                                                                        |
| [Decomposition](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb) | 質問を小さなサブ問題に分解できる場合                                    | 質問を一連のサブ問題やサブ質問に分解します。これらは順次（最初の回答＋検索を使用して次を回答）または並行して（各回答を統合して最終的な回答を生成）解決することができます。                                                           |
| [Step-back](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)     | より高レベルな概念的理解が必要な場合                                      | 最初にLLMに対して、より高次の概念や原則についての一般的なステップバック質問を促し、それに関連する事実を取得します。この基盤を使用してユーザーの質問に答える助けとします。 [論文](https://arxiv.org/pdf/2310.06117).                                            |
| [HyDE](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_5_to_9.ipynb)          | ユーザーの生の入力を使用して関連ドキュメントを取得するのが困難な場合                 | 質問を仮想的なドキュメントに変換し、仮想ドキュメントを使用して実際のドキュメントを取得します。ドキュメント間の類似性検索により、より関連性の高い一致を生成できるという前提に基づいています。 [論文](https://arxiv.org/abs/2212.10496). |

例えば、クエリ分解はプロンプトとサブ質問のリストを強制する構造化出力を使用して簡単に実行できます。  
これらのサブ質問は、下流の検索システムで順次または並行して実行することができます。

```python
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

# 出力構造を強制するためのpydanticモデルを定義
class Questions(BaseModel):
    questions: List[str] = Field(
        description="入力クエリに関連するサブ質問のリスト。"
    )

# モデルのインスタンスを作成し、出力構造を強制
model = ChatOpenAI(model="gpt-4o", temperature=0) 
structured_model = model.with_structured_output(Questions)

# システムプロンプトを定義
system = """あなたは、入力された質問に関連する複数のサブ質問を生成する役に立つアシスタントです。\n
目標は、入力を一連のサブ問題／サブ質問に分解し、それぞれ個別に回答できるようにすることです。\n"""

# 質問をモデルに渡す
question = ""LLMを活用した自律型エージェントシステムの主要な構成要素は何ですか？"""
questions = structured_model.invoke([SystemMessage(content=system)]+[HumanMessage(content=question)])
```

:::tip

RAG from Scratchの動画で、いくつかの具体的なアプローチを確認できます：
- [Multi-query](https://youtu.be/JChPi0CRnDY?feature=shared)
- [Decomposition](https://youtu.be/h0OPWlEOank?feature=shared)
- [Step-back](https://youtu.be/xn1jEjRyJ2U?feature=shared)
- [HyDE](https://youtu.be/SaDzIVkYqyY?feature=shared)

:::

### Query construction

クエリ分析では、自然言語クエリを専門的なクエリ言語やフィルターに変換することにも焦点を当てることができます。  
この変換は、構造化データや半構造化データを格納するさまざまなタイプのデータベースと効果的にやり取りするために非常に重要です。

1. **Structured Data examples**: リレーショナルデータベースやグラフデータベースでは、ドメイン固有言語（DSL）を使用してデータをクエリします。
   - **Text-to-SQL**: [自然言語をSQLに変換](https://paperswithcode.com/task/text-to-sql) し、リレーショナルデータベースにクエリを実行します。
   - **Text-to-Cypher**: [自然言語をCypherに変換](https://neo4j.com/labs/neodash/2.4/user-guide/extensions/natural-language-queries/) し、グラフデータベースにクエリを実行します。

2. **Semi-structured Data examples**: ベクトルストアでは、セマンティック検索とメタデータフィルタリングを組み合わせたクエリが使用されます。
   - **Natural Language to Metadata Filters**: ユーザークエリを [適切なメタデータフィルター](https://docs.pinecone.io/guides/data/filter-with-metadata)に変換します。

これらのアプローチは、ユーザーの意図と異なるデータストレージシステムの特定のクエリ要件とのギャップを埋めるためにモデルを活用します。以下は、一般的な技術の一覧です：

| Name                                     | When to Use                                                                                                                          | Description                                                                                                                                                                                                                                          |
|------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Self Query](/docs/how_to/self_query/)   | ユーザーが、テキストの類似性ではなくメタデータに基づいてドキュメントを取得する方が適している質問をしている場合 | これは、LLMを使用してユーザー入力を次の2つに変換します：(1) セマンティックに検索する文字列、(2) それに伴うメタデータフィルター。この方法は、質問がドキュメントのコンテンツ自体ではなくメタデータに関するものである場合に役立ちます。 |
| [Text to SQL](/docs/tutorials/sql_qa/)   | ユーザーが、SQLを介してアクセス可能なリレーショナルデータベースに格納された情報を必要とする質問をしている場合                         | これは、LLMを使用してユーザー入力をSQLクエリに変換します。                                                                                                                                                                                           |
| [Text-to-Cypher](/docs/tutorials/graph/) | ユーザーが、Cypherを介してアクセス可能なグラフデータベースに格納された情報を必要とする質問をしている場合                            | これは、LLMを使用してユーザー入力をCypherクエリに変換します。                                                                                                                                                                                     |

以下は、`SelfQueryRetriever`を使用して自然言語クエリをメタデータフィルターに変換する方法の例です。

```python
metadata_field_info = schema_for_metadata 
document_content_description = "映画の簡潔な要約"
llm = ChatOpenAI(temperature=0)
retriever = SelfQueryRetriever.from_llm(
    llm,
    vectorstore,
    document_content_description,
    metadata_field_info,
)
```

:::info[Further reading]

* Text-to-SQL、Text-to-Cypher、およびメタデータフィルターのクエリ分析に関するチュートリアルをご覧ください。
* [クエリ構築に関するブログ記事](https://blog.langchain.dev/query-construction/)をご覧ください。
* RAG from Scratchの[クエリ構築に関する動画](https://youtu.be/kl6NwWYxvbM?feature=shared)をご覧ください。

::: 

## 情報検索

### 一般的な検索システム

#### Lexical search indexes

多くの検索エンジンは、クエリ内の単語を各ドキュメント内の単語と一致させることに基づいています。このアプローチはレキシカル検索と呼ばれ、[通常は単語頻度に基づいたアルゴリズム](https://cameronrwolfe.substack.com/p/the-basics-of-ai-powered-vector-search?utm_source=profile&utm_medium=reader2)を使用します。  
直感的な考え方としては、ユーザーのクエリと特定のドキュメントの両方に頻繁に現れる単語があれば、そのドキュメントは適合性が高い可能性があるというものです。 

このアプローチを実装するために使用される具体的なデータ構造は、しばしば[反転インデックス](https://www.geeksforgeeks.org/inverted-index/)です。  
このタイプのインデックスには単語のリストと、各単語がさまざまなドキュメントで現れる位置のリストへのマッピングが含まれます。  
このデータ構造を使用すると、検索クエリ内の単語をそれが現れるドキュメントに効率的に一致させることが可能になります。  
[BM25](https://en.wikipedia.org/wiki/Okapi_BM25#:~:text=BM25%20is%20a%20bag%2Dof,slightly%20different%20components%20and%20parameters.)や[TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)は、[人気のあるレキシカル検索アルゴリズム](https://cameronrwolfe.substack.com/p/the-basics-of-ai-powered-vector-search?utm_source=profile&utm_medium=reader2)の例です。

:::info[Further reading]

* [BM25](/docs/integrations/retrievers/bm25/) レトリーバー統合をご覧ください。
* [Elasticsearch](/docs/integrations/retrievers/elasticsearch_retriever/) レトリーバー統合をご覧ください。

::: 

#### Vector indexes

ベクトルインデックスは、非構造化データをインデックス化して保存するための代替手段です。  
詳細な概要については、ベクトルストアに関する概念ガイドをご覧ください。  
簡単に言えば、単語頻度を使用するのではなく、ベクトルストアは埋め込みモデルを使用して、ドキュメントを高次元のベクトル表現に圧縮します。  
これにより、コサイン類似度のような単純な数学的操作を使用して埋め込みベクトル間の効率的な類似性検索が可能になります。

:::info[Further reading]

* ベクトルストアを操作するためのハウツーガイドをご覧ください。
* ベクトルストア統合の一覧をご覧ください。
* ベクトル検索の基本に関するCameron Wolfeの [ブログ記事](https://cameronrwolfe.substack.com/p/the-basics-of-ai-powered-vector-search?utm_source=profile&utm_medium=reader2) をご覧ください。

:::

#### Relational databases

リレーショナルデータベースは、多くのアプリケーションで使用される構造化データストレージの基本的なタイプです。  
これらは、定義済みのスキーマを持つテーブルにデータを編成し、各テーブルがエンティティまたは関係を表します。  
データは行（レコード）と列（属性）に格納され、SQL（構造化クエリ言語）を通じて効率的にクエリと操作を行うことができます。  
リレーショナルデータベースは、データの整合性を維持し、複雑なクエリをサポートし、異なるデータエンティティ間の関係を処理するのに優れています。

:::info[Further reading]

* SQLデータベースの操作に関するチュートリアルをご覧ください。
* SQLデータベースツールキットをご覧ください。

:::

#### Graph databases

グラフデータベースは、高度に相互接続されたデータを保存および管理するために設計された特殊なデータベースです。  
従来のリレーショナルデータベースとは異なり、グラフデータベースは、ノード（エンティティ）、エッジ（関係）、プロパティから成る柔軟な構造を使用します。  
この構造により、複雑で相互接続されたデータの効率的な表現とクエリが可能になります。  
グラフデータベースは、ノード、エッジ、プロパティで構成されるグラフ構造にデータを格納します。  
特に、データポイント間の複雑な関係を保存およびクエリするのに有用で、ソーシャルネットワーク、サプライチェーン管理、不正検出、レコメンデーションサービスなどに適しています。

:::info[Further reading]

* グラフデータベースの操作に関するチュートリアルをご覧ください。
* グラフデータベース統合の一覧をご覧ください。
* Neo4jによる [LangChainスターターキット](https://neo4j.com/developer-blog/langchain-neo4j-starter-kit/)をご覧ください。

:::

### Retriever  

LangChainは、retrieverという概念を通じて、さまざまな検索システムとやり取りするための統一されたインターフェースを提供します。このインターフェースはシンプルです：

1. 入力: クエリ（文字列）
2. 出力: ドキュメントのリスト（標準化されたLangChainの[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)オブジェクト）

前述の検索システムのいずれかを使用してレトリーバーを作成できます。  
ここで、クエリ分析の技術が特に役立ちます。これにより、通常は構造化されたクエリ言語を必要とするデータベースに対して、自然言語インターフェースを提供できます。  
たとえば、SQLデータベース用にテキストからSQLへの変換を利用したレトリーバーを構築できます。これにより、自然言語のクエリ（文字列）が裏でSQLクエリに変換されます。  
基盤となる検索システムに関係なく、LangChainのすべてのレトリーバーは共通のインターフェースを共有しています。  
シンプルなinvokeメソッドを使用して操作できます：

```python
docs = retriever.invoke(query)
```

:::info[Further reading]

* レトリーバーに関する概念ガイドをご覧ください。
* レトリーバーの操作に関するハウツーガイドをご覧ください。

:::
